{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOY1qn6yNHiEK34GBQcCCx0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQvjE-i0tNkr","executionInfo":{"status":"ok","timestamp":1721723419152,"user_tz":-330,"elapsed":476,"user":{"displayName":"JANANI P 2022-2026","userId":"15722373385076290454"}},"outputId":"cf840f8d-03e8-43ca-9c4b-36bca30e595f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unigrams:\n","[('.', 4), ('is', 3), (',', 3), ('this', 2), ('corpus', 2), ('the', 2), ('a', 1), ('sample', 1), ('text', 1), ('used', 1), ('to', 1), ('demonstrate', 1), ('generation', 1), ('of', 1), ('unigrams', 1), ('bigrams', 1), ('and', 1), ('trigrams', 1), ('bigram', 1), ('probabilities', 1), ('are', 1), ('also', 1), ('calculated', 1), ('lastly', 1), ('next', 1), ('word', 1), ('prediction', 1), ('performed', 1)]\n","\n","Bigrams:\n","[(('this', 'is'), 1), (('is', 'a'), 1), (('a', 'sample'), 1), (('sample', 'text'), 1), (('text', 'corpus'), 1), (('corpus', '.'), 1), (('.', 'this'), 1), (('this', 'corpus'), 1), (('corpus', 'is'), 1), (('is', 'used'), 1), (('used', 'to'), 1), (('to', 'demonstrate'), 1), (('demonstrate', 'the'), 1), (('the', 'generation'), 1), (('generation', 'of'), 1), (('of', 'unigrams'), 1), (('unigrams', ','), 1), ((',', 'bigrams'), 1), (('bigrams', ','), 1), ((',', 'and'), 1), (('and', 'trigrams'), 1), (('trigrams', '.'), 1), (('.', 'the'), 1), (('the', 'bigram'), 1), (('bigram', 'probabilities'), 1), (('probabilities', 'are'), 1), (('are', 'also'), 1), (('also', 'calculated'), 1), (('calculated', '.'), 1), (('.', 'lastly'), 1), (('lastly', ','), 1), ((',', 'next'), 1), (('next', 'word'), 1), (('word', 'prediction'), 1), (('prediction', 'is'), 1), (('is', 'performed'), 1), (('performed', '.'), 1)]\n","\n","Trigrams:\n","[(('this', 'is', 'a'), 1), (('is', 'a', 'sample'), 1), (('a', 'sample', 'text'), 1), (('sample', 'text', 'corpus'), 1), (('text', 'corpus', '.'), 1), (('corpus', '.', 'this'), 1), (('.', 'this', 'corpus'), 1), (('this', 'corpus', 'is'), 1), (('corpus', 'is', 'used'), 1), (('is', 'used', 'to'), 1), (('used', 'to', 'demonstrate'), 1), (('to', 'demonstrate', 'the'), 1), (('demonstrate', 'the', 'generation'), 1), (('the', 'generation', 'of'), 1), (('generation', 'of', 'unigrams'), 1), (('of', 'unigrams', ','), 1), (('unigrams', ',', 'bigrams'), 1), ((',', 'bigrams', ','), 1), (('bigrams', ',', 'and'), 1), ((',', 'and', 'trigrams'), 1), (('and', 'trigrams', '.'), 1), (('trigrams', '.', 'the'), 1), (('.', 'the', 'bigram'), 1), (('the', 'bigram', 'probabilities'), 1), (('bigram', 'probabilities', 'are'), 1), (('probabilities', 'are', 'also'), 1), (('are', 'also', 'calculated'), 1), (('also', 'calculated', '.'), 1), (('calculated', '.', 'lastly'), 1), (('.', 'lastly', ','), 1), (('lastly', ',', 'next'), 1), ((',', 'next', 'word'), 1), (('next', 'word', 'prediction'), 1), (('word', 'prediction', 'is'), 1), (('prediction', 'is', 'performed'), 1), (('is', 'performed', '.'), 1)]\n","\n","Bigram Probabilities:\n","P(is|this) = 0.5000\n","P(corpus|this) = 0.5000\n","P(a|is) = 0.3333\n","P(used|is) = 0.3333\n","P(performed|is) = 0.3333\n","P(sample|a) = 1.0000\n","P(text|sample) = 1.0000\n","P(corpus|text) = 1.0000\n","P(.|corpus) = 0.5000\n","P(is|corpus) = 0.5000\n","P(this|.) = 0.3333\n","P(the|.) = 0.3333\n","P(lastly|.) = 0.3333\n","P(to|used) = 1.0000\n","P(demonstrate|to) = 1.0000\n","P(the|demonstrate) = 1.0000\n","P(generation|the) = 0.5000\n","P(bigram|the) = 0.5000\n","P(of|generation) = 1.0000\n","P(unigrams|of) = 1.0000\n","P(,|unigrams) = 1.0000\n","P(bigrams|,) = 0.3333\n","P(and|,) = 0.3333\n","P(next|,) = 0.3333\n","P(,|bigrams) = 1.0000\n","P(trigrams|and) = 1.0000\n","P(.|trigrams) = 1.0000\n","P(probabilities|bigram) = 1.0000\n","P(are|probabilities) = 1.0000\n","P(also|are) = 1.0000\n","P(calculated|also) = 1.0000\n","P(.|calculated) = 1.0000\n","P(,|lastly) = 1.0000\n","P(word|next) = 1.0000\n","P(prediction|word) = 1.0000\n","P(is|prediction) = 1.0000\n","P(.|performed) = 1.0000\n","\n","Predicted next word for 'this': is\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import nltk\n","from nltk import word_tokenize, FreqDist\n","from nltk.util import ngrams\n","from collections import defaultdict, Counter\n","import random\n","\n","nltk.download('punkt')\n","text = \"This is a sample text corpus. This corpus is used to demonstrate the generation of unigrams, bigrams, and trigrams. The bigram probabilities are also calculated. Lastly, next word prediction is performed.\"\n","tokens = word_tokenize(text.lower())\n","\n","# Unigrams\n","unigrams = tokens\n","unigram_freq = FreqDist(unigrams)\n","\n","# Bigrams\n","bigrams = list(ngrams(tokens, 2))\n","bigram_freq = FreqDist(bigrams)\n","\n","# Trigrams\n","trigrams = list(ngrams(tokens, 3))\n","trigram_freq = FreqDist(trigrams)\n","\n","# Bigram Probabilities\n","bigram_probabilities = defaultdict(lambda: defaultdict(lambda: 0))\n","for w1, w2 in bigrams:\n","    bigram_probabilities[w1][w2] += 1\n","\n","for w1 in bigram_probabilities:\n","    total_count = float(sum(bigram_probabilities[w1].values()))\n","    for w2 in bigram_probabilities[w1]:\n","        bigram_probabilities[w1][w2] /= total_count\n","\n","# Next word prediction\n","def predict_next_word(prev_word, bigram_probabilities):\n","    next_word_probs = bigram_probabilities[prev_word]\n","    if not next_word_probs:\n","        return None\n","    next_word = max(next_word_probs, key=next_word_probs.get)\n","    return next_word\n","\n","\n","print(\"Unigrams:\")\n","print(unigram_freq.most_common())\n","\n","print(\"\\nBigrams:\")\n","print(bigram_freq.most_common())\n","\n","print(\"\\nTrigrams:\")\n","print(trigram_freq.most_common())\n","\n","print(\"\\nBigram Probabilities:\")\n","for w1 in bigram_probabilities:\n","    for w2 in bigram_probabilities[w1]:\n","        print(f\"P({w2}|{w1}) = {bigram_probabilities[w1][w2]:.4f}\")\n","\n","\n","prev_word = 'this'\n","predicted_next_word = predict_next_word(prev_word, bigram_probabilities)\n","print(f\"\\nPredicted next word for '{prev_word}': {predicted_next_word}\")"]}]}